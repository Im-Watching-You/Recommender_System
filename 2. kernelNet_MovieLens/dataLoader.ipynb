{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date: 01.08.2020\n",
    "# MovieLens: Loading Data\n",
    "# Coder: Maksym Chernozhukov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Baseline\n",
    "* Filter 1 (Apriory Prediction)\n",
    "* Filter 2 (Apriory Fuzzy Average Strategy)\n",
    "* Filter 3 (Apriory Fuzzy Removal Strategy)\n",
    "* Filter 4 (Fuzzy Prediction)\n",
    "* Fading Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "# Epoch: 15     RMSE: 0.822971165\n",
    "\n",
    "# FILTER 1\n",
    "# Epoch: 15     RMSE: 0.822302     MAE: 0.641717     Filter 1     1M     N=50     diff=1.5     minSup=430     37.93 min! *\n",
    "# Epoch: 13     RMSE: 0.823840     MAE: 0.642738     Filter 1     1M     N=5      diff=2.0     minSup=430     42.25 min!\n",
    "# Epoch: 15     RMSE: 0.822302     MAE: 0.641717     dataset_1M_50_1.5_430     *\n",
    "# Epoch: 16     RMSE: 0.822875     MAE: 0.642104     dataset_1M_50_1.5_430_svd **\n",
    "# Epoch: 15     RMSE: 0.823840     MAE: 0.642738     dataset_1M_5_2.0_430_knn  ***\n",
    "\n",
    "# FILTER 2\n",
    "# Option: 1     RMSE: 0.821129     MAE: 0.641357     Filter 2     1M     N=5     minSup=430     38.44 min!  *\n",
    "# Epoch: 15     RMSE: 0.821690     MAE: 0.641569 avg\n",
    "\n",
    "# FILTER 3\n",
    "# Option: 2     RMSE: 0.821301     MAE: 0.640002     Filter 3     1M     N=1     minSup=200     38.23 min!  **\n",
    "# Epoch: 15     RMSE: 0.821078     MAE: 0.641260 rmv\n",
    "\n",
    "# FILTER 4\n",
    "# Epoch: 19     RMSE: 0.741016     MAE: 0.588022     TRESHOLD = 1\n",
    "# Epoch: 14     RMSE: 0.807681     MAE: 0.630654     TRESHOLD = 1.5\n",
    "# Epoch: 15     RMSE: 0.818303     MAE: 0.638466     TRESHOLD = 1.6   *\n",
    "# Epoch: 16     RMSE: 0.822527     MAE: 0.641712     TRESHOLD = 1.7   **\n",
    "# Epoch: 15     RMSE: 0.823252     MAE: 0.642404     TRESHOLD = 1.8\n",
    "\n",
    "# FADING FILTER\n",
    "# Test 1: timestamp_description [min, 25%, 50%, 75%, max]\n",
    "# 1. Epoch: 15      RMSE: 0.8034054        Note: Float\n",
    "# Epoch: 15      RMSE: 0.799343      MAE: 0.629337\n",
    "\n",
    "# Test 2: timestamp_description [min, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, max]\n",
    "# 1. Epoch: 17      RMSE: 0.7883963        Note: Float\n",
    "# Epoch: 13      RMSE: 0.789561      MAE: 0.622323\n",
    "\n",
    "# Test 2: timestamp_description [min, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, max]. Version 2.0\n",
    "# 1. Epoch: 16      RMSE: 0.803493        Note: Float\n",
    "# Epoch: 13      RMSE: 0.804322      MAE: 0.632073\n",
    "\n",
    "# Test 2: timestamp_description [min, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, max]. Version 3.0\n",
    "# 1. Epoch: 16      RMSE: 0.804867        Note: Float\n",
    "# Epoch: 14      RMSE: 0.805338      MAE: 0.632460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from time import time\n",
    "# from numpy import load\n",
    "\n",
    "\n",
    "# def loadData(path='./', valfrac=0.1, delimiter='::', seed=1234, transpose=False):\n",
    "#     '''\n",
    "#     Loads the Dataset: 'ml-1M.dat'\n",
    "    \n",
    "#     :param path: path to the ratings file\n",
    "#     :param valfrac: fraction of data to use for validation\n",
    "#     :param delimiter: delimiter used in data file\n",
    "#     :param seed: random seed for validation splitting\n",
    "#     :param transpose: flag to transpose output matrices (swapping users with movies)\n",
    "#     :return: train ratings (n_u, n_m), valid ratings (n_u, n_m)\n",
    "#     '''\n",
    "#     tic = time()\n",
    "#     np.random.seed(seed)\n",
    "    \n",
    "#     print('reading data...')\n",
    "# # /////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "#     # Baseline\n",
    "# #     data = np.loadtxt(path, skiprows=0, delimiter=delimiter).astype('int32')\n",
    "\n",
    "#     # Filter 1\n",
    "# #     data = load('./datasets/filter_1/dataset_1M_50_1.5_430.npy')      # DL\n",
    "# #     data = load('./datasets/filter_1/dataset_1M_50_1.5_430_svd.npy')  # svd\n",
    "# #     data = load('./datasets/filter_1/dataset_1M_5_2.0_430_knn.npy')   # knn\n",
    "\n",
    "#     # Filter 2,3\n",
    "# #     data = load('./datasets/filter_2/dataset_1M_5_430_avg.npy')       # Average\n",
    "# #     data = load('./datasets/filter_2/dataset_1M_1_200_rmv.npy')       # Removal\n",
    "\n",
    "#     # Filter 4\n",
    "# #     data = load('./datasets/filter_4/dataset_1M_1.6.npy')      # Fuzzy method + knn\n",
    "\n",
    "#     # Fading filter\n",
    "# #     data = load('./datasets/fading/fading_filter_0.0V.npy')       # 0.0 version\n",
    "# #     data = load('./datasets/fading/fading_filter_1.0V.npy')       # 1.0 version\n",
    "# #     data = load('./datasets/fading/fading_filter_2.0V.npy')       # 2.0 version\n",
    "# #     data = load('./datasets/fading/fading_filter_3.0V.npy')       # 3.0 version\n",
    "    \n",
    "# # /////////////////////////////////////////////////////////////////////////////////    \n",
    "#     print('\\ndata read in: {:0.2f} seconds!'.format(time() - tic))\n",
    "    \n",
    "#     users = np.unique(data[:, 0]).tolist() # list of unique users\n",
    "#     items = np.unique(data[:, 1]).tolist() # list of unique items\n",
    "    \n",
    "#     n_u = len(users)     # number of users\n",
    "#     n_m = len(items)     # number of movies\n",
    "#     n_r = data.shape[0]  # number of ratings\n",
    "\n",
    "#     # these dictionaries define a mapping from user/movie id to to user/movie number (contiguous from zero)\n",
    "#     udict = {}        # {id_u: index(0..6039)}\n",
    "#     for i, u in enumerate(users):\n",
    "#         udict[u] = i\n",
    "#     mdict = {}        # {id_m: index(0..3705)}\n",
    "#     for i, m in enumerate(items):\n",
    "#         mdict[m] = i\n",
    "\n",
    "#     # shuffle indices\n",
    "#     idx = np.arange(n_r)\n",
    "#     np.random.shuffle(idx)\n",
    "\n",
    "#     trainRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "#     validRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "\n",
    "#     for i in range(n_r):\n",
    "#         u_id = data[idx[i], 0]\n",
    "#         m_id = data[idx[i], 1]\n",
    "#         r = data[idx[i], 2]\n",
    "\n",
    "#         # the first few ratings of the shuffled data array are validation data\n",
    "#         if i <= valfrac * n_r:\n",
    "#             validRatings[udict[u_id], mdict[m_id]] = float(r)     # [index(0..6039), index(0..3705)] = r\n",
    "#         # the rest are training data\n",
    "#         else:\n",
    "#             trainRatings[udict[u_id], mdict[m_id]] = float(r)     # [index(0..6039), index(0..3705)] = r\n",
    "\n",
    "#     if transpose:\n",
    "#         trainRatings = trainRatings.T\n",
    "#         validRatings = validRatings.T\n",
    "\n",
    "#     print('loaded dense data matrix')\n",
    "#     print('\\nAll data preprocessed: {:0.2f} seconds!'.format(time() - tic))\n",
    "#     print('\\n------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "#     return trainRatings, validRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from time import time\n",
    "\n",
    "\n",
    "# def loadData(path='./', valfrac=0.1, delimiter='::', seed=1234, transpose=False):\n",
    "#     '''\n",
    "#     loads ml-1m data\n",
    "\n",
    "#     :param path: path to the ratings file\n",
    "#     :param valfrac: fraction of data to use for validation\n",
    "#     :param delimiter: delimiter used in data file\n",
    "#     :param seed: random seed for validation splitting\n",
    "#     :param transpose: flag to transpose output matrices (swapping users with movies)\n",
    "#     :return: train ratings (n_u, n_m), valid ratings (n_u, n_m)\n",
    "#     '''\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "#     tic = time()\n",
    "#     print('reading data...')\n",
    "#     data = np.loadtxt(path, skiprows=0, delimiter=delimiter).astype('int32')\n",
    "#     print('data read in', time() - tic, 'seconds')\n",
    "\n",
    "#     n_u = np.unique(data[:, 0]).shape[0]  # number of users\n",
    "#     n_m = np.unique(data[:, 1]).shape[0]  # number of movies\n",
    "#     n_r = data.shape[0]  # number of ratings\n",
    "\n",
    "#     # these dictionaries define a mapping from user/movie id to to user/movie number (contiguous from zero)\n",
    "#     udict = {}\n",
    "#     for i, u in enumerate(np.unique(data[:, 0]).tolist()):\n",
    "#         udict[u] = i\n",
    "#     mdict = {}\n",
    "#     for i, m in enumerate(np.unique(data[:, 1]).tolist()):\n",
    "#         mdict[m] = i\n",
    "\n",
    "#     # shuffle indices\n",
    "#     idx = np.arange(n_r)\n",
    "#     np.random.shuffle(idx)\n",
    "\n",
    "#     trainRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "#     validRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "\n",
    "#     for i in range(n_r):\n",
    "#         u_id = data[idx[i], 0]\n",
    "#         m_id = data[idx[i], 1]\n",
    "#         r = data[idx[i], 2]\n",
    "\n",
    "#         # the first few ratings of the shuffled data array are validation data\n",
    "#         if i <= valfrac * n_r:\n",
    "#             validRatings[udict[u_id], mdict[m_id]] = int(r)\n",
    "#         # the rest are training data\n",
    "#         else:\n",
    "#             trainRatings[udict[u_id], mdict[m_id]] = int(r)\n",
    "\n",
    "#     if transpose:\n",
    "#         trainRatings = trainRatings.T\n",
    "#         validRatings = validRatings.T\n",
    "\n",
    "#     print('loaded dense data matrix')\n",
    "\n",
    "#     return trainRatings, validRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from numpy import load\n",
    "\n",
    "\n",
    "def loadData(path='./', valfrac=0.1, delimiter='::', seed=1234, transpose=False):\n",
    "    '''\n",
    "    Loads the Dataset: 'ml-1M.dat'\n",
    "    \n",
    "    :param path: path to the ratings file\n",
    "    :param valfrac: fraction of data to use for validation\n",
    "    :param delimiter: delimiter used in data file\n",
    "    :param seed: random seed for validation splitting\n",
    "    :param transpose: flag to transpose output matrices (swapping users with movies)\n",
    "    :return: train ratings (n_u, n_m), valid ratings (n_u, n_m)\n",
    "    '''\n",
    "    tic = time()\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print('reading data...')\n",
    "    data = np.loadtxt(path, skiprows=0, delimiter=delimiter).astype('int32') \n",
    "    print('\\ndata read in: {:0.2f} seconds!'.format(time() - tic))\n",
    "    \n",
    "    users = np.unique(data[:, 0]).tolist() # list of unique users\n",
    "    items = np.unique(data[:, 1]).tolist() # list of unique items\n",
    "    \n",
    "    n_u = len(users)     # number of users\n",
    "    n_m = len(items)     # number of movies\n",
    "    n_r = data.shape[0]  # number of ratings\n",
    "\n",
    "    # these dictionaries define a mapping from user/movie id to to user/movie number (contiguous from zero)\n",
    "    udict = {}        # {id_u: index(0..6039)}\n",
    "    for i, u in enumerate(users):\n",
    "        udict[u] = i\n",
    "    mdict = {}        # {id_m: index(0..3705)}\n",
    "    for i, m in enumerate(items):\n",
    "        mdict[m] = i\n",
    "\n",
    "    trainRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "    validRatings = np.zeros((n_u, n_m), dtype='float32') \n",
    "    \n",
    "# /////////////////////////////////////////////////////////////////////////////////    \n",
    "    \n",
    "        # Filter 1\n",
    "#     train_data = load('./datasets/filter_1/dataset_1M_50_1.5_430_svd.npy')  # svd\n",
    "#     train_data = load('./datasets/filter_1/dataset_1M_5_2.0_430_knn.npy')   # knn\n",
    "\n",
    "    # Filter 2\n",
    "#     train_data = load('./datasets/filter_2/dataset_1M_5_430_avg.npy')       # Average\n",
    "\n",
    "    # Filter 3\n",
    "#     train_data = load('./datasets/filter_3/dataset_1M_1_200_rmv.npy')       # Removal\n",
    "\n",
    "    # Filter 4\n",
    "#     train_data = load('./datasets/filter_4/dataset_1M_1.7.npy')             # Fuzzy method + knn\n",
    "    \n",
    "    # Final Filter\n",
    "    train_data = load('./datasets/final_filter/dataset_1M_1.7F_W.npy')             # DL + \n",
    "\n",
    "    # Fading filter\n",
    "#     train_data = load('./datasets/fading/fading_filter_0.0V.npy')       # 0.0 version\n",
    "#     train_data = load('./datasets/fading/fading_filter_1.0V.npy')       # 1.0 version\n",
    "#     train_data = load('./datasets/fading/fading_filter_2.0V.npy')       # 2.0 version\n",
    "#     train_data = load('./datasets/fading/fading_filter_3.0V.npy')       # 3.0 version\n",
    "    \n",
    "# ///////////////////////////////////////////////////////////////////////////////// \n",
    "#     train_data = load('./datasets/main/train_set_1M.npy')\n",
    "    test_data = load('./datasets/main/test_set_1M.npy')\n",
    "\n",
    "    for i in range(train_data.shape[0]):\n",
    "        u_id = train_data[i, 0]\n",
    "        m_id = train_data[i, 1]\n",
    "        r = train_data[i, 2]\n",
    "\n",
    "        trainRatings[udict[u_id], mdict[m_id]] = int(r)     # [index(0..6039), index(0..3705)] = r\n",
    "\n",
    "    for i in range(test_data.shape[0]):\n",
    "        u_id = test_data[i, 0]\n",
    "        m_id = test_data[i, 1]\n",
    "        r = test_data[i, 2]\n",
    "\n",
    "        validRatings[udict[u_id], mdict[m_id]] = int(r)     # [index(0..6039), index(0..3705)] = r\n",
    "\n",
    "    if transpose:\n",
    "        trainRatings = trainRatings.T\n",
    "        validRatings = validRatings.T\n",
    "\n",
    "    print('loaded dense data matrix')\n",
    "    print('\\nAll data preprocessed: {:0.2f} seconds!'.format(time() - tic))\n",
    "    print('\\n------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "    return trainRatings, validRatings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
