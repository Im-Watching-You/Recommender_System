{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline    RMSE: 0.822971165     36.18 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mll-100K: 100 unints \n",
    "# 1. Epoch: 14     Validation RMSE: 0.843645     Train RMSE: 0.813047       2.52 min!  old ml-100K\n",
    "# 2. Epoch: 19     Validation RMSE: 0.853146     Train RMSE: 0.807953       2.52 min!  old ml-100K\n",
    "# 3. Epoch: 19     Validation RMSE: 0.913492     Train RMSE: 0.881876       1.58 min!  new ml-100K\n",
    "\n",
    "# mll-100K: 500 unints \n",
    "# 4. Epoch: 19     Validation RMSE: 0.898440     Train RMSE: 0.852413       6.07 min!  new ml-100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "# tr, vr = loadData('./datasets/ml-100K.csv', valfrac=0.25, delimiter='::', seed=seed, transpose=True) # .csv file\n",
    "# tr, vr, anomalousItemsPerUserList = loadData('./datasets/ml-1M.dat', valfrac=0.1, delimiter='::', seed=seed, transpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae_valid = []\n",
    "# MAE = abs(vm * (np.clip(pre, 1., 5.) - vr)).sum() / vm.sum() # compute validation error MAE\n",
    "# mae_valid.append(MAE) # MAE\n",
    "# print('Epoch: {0}\\tRMSE: {1:0.6f}\\tMAE: {2:0.6f}'.format(stop_epoch, min(valid), min(mae_valid) ) )\n",
    "\n",
    "# x = 100 - ((new / base) * 100%) on 1% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1  Sparse FC(1M)     RMSE: 0.824     Paper: Kernelized Synaptic Weight Matrices     2018\n",
    "# 7  Sparse FC(10M)    RMSE: 0.769     Paper: Kernelized Synaptic Weight Matrices     2018\n",
    "\n",
    "# 1  Bayesian timeSVD++ flipped(10M)    RMSE: 0.7485\n",
    "# Paper: On the Difficulty of Evaluating Baselines: A Study on Recommender Systems    2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of rules in dict\n",
    "# count = 0\n",
    "# for i in range(6040):\n",
    "#     count += len(anomalousItemsPerUserList[i])\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of rules wich = 5 per user\n",
    "# count = 0\n",
    "# for i in range(6040):\n",
    "#     x = len(anomalousItemsPerUserList[i])\n",
    "#     if x >= 5:\n",
    "#         count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import save, load\n",
    "\n",
    "# predicted_matrix = pre.T\n",
    "\n",
    "# save('predicted_matrix_1M.npy', predicted_matrix)\n",
    "# final_matrix_load = load('predicted_matrix_1M.npy')\n",
    "\n",
    "# print(final_matrix_load)\n",
    "# print(np.shape(predicted_matrix), (final_matrix_load == predicted_matrix).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from time import time\n",
    "\n",
    "\n",
    "# def loadData(path='./', valfrac=0.1, delimiter='::', seed=1234, transpose=False):\n",
    "#     '''\n",
    "#     Loads the Dataset: 'ml-1M.dat'\n",
    "    \n",
    "#     :param path: path to the ratings file\n",
    "#     :param valfrac: fraction of data to use for validation\n",
    "#     :param delimiter: delimiter used in data file\n",
    "#     :param seed: random seed for validation splitting\n",
    "#     :param transpose: flag to transpose output matrices (swapping users with movies)\n",
    "#     :return: train ratings (n_u, n_m), valid ratings (n_u, n_m)\n",
    "#     '''\n",
    "#     tic = time()\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "    \n",
    "#     print('reading data...')\n",
    "#     data = np.loadtxt(path, skiprows=0, delimiter=delimiter).astype('int32')  # .dat file\n",
    "#     print('\\ndata read in: {:0.2f} seconds!'.format(time() - tic))\n",
    "\n",
    "#     data_csv = pd.DataFrame(data, columns = ['user', 'item', 'rating', 'timestamp'])\n",
    "#     data_csv.sort_values(['user', 'item'], ascending=[True, True], inplace=True)\n",
    "#     data_csv.reset_index(inplace=True)\n",
    "#     data_csv.drop('index', axis=1, inplace=True)\n",
    "\n",
    "#     # MovieLens 1M\n",
    "#     N = 50\n",
    "#     diff = 1.5\n",
    "#     minSup = 430\n",
    "\n",
    "#     users = np.unique(data[:, 0]).tolist() # list of unique users\n",
    "#     items = np.unique(data[:, 1]).tolist() # list of unique items\n",
    "    \n",
    "#     n_u = len(users)     # number of users\n",
    "#     n_m = len(items)     # number of movies\n",
    "#     n_r = data.shape[0]  # number of ratings\n",
    "\n",
    "#     # these dictionaries define a mapping from user/movie id to to user/movie number (contiguous from zero)\n",
    "#     udict = {}        # {id_u: index(0..6039)}\n",
    "#     for i, u in enumerate(users):\n",
    "#         udict[u] = i\n",
    "#     mdict = {}        # {id_m: index(0..3705)}\n",
    "#     for i, m in enumerate(items):\n",
    "#         mdict[m] = i\n",
    "\n",
    "#     support_matrix_users = np.zeros((n_u, 16), dtype='int32')\n",
    "#     support_matrix_items = np.zeros((n_m, 16), dtype='int32')\n",
    "#     matrix = np.zeros((n_u, n_m), dtype='float')    \n",
    "    \n",
    "#     for i in range(n_r):\n",
    "#         u_id = data[i, 0]\n",
    "#         m_id = data[i, 1]\n",
    "#         r = data[i, 2]\n",
    "\n",
    "#         matrix[udict[u_id], mdict[m_id]] = int(r)\n",
    "    \n",
    "    \n",
    "#     def userItemSet(regul):\n",
    "#         temp_dic = dict()       \n",
    "#         for reg in regul:\n",
    "#             temp = []\n",
    "#             arc1 = 0\n",
    "#             arc2 = 0\n",
    "#             arc3 = 0\n",
    "\n",
    "#             for i, r in enumerate(reg[1:6]):\n",
    "#                 if r!=0:\n",
    "#                     arc1 = i+1\n",
    "\n",
    "#             for i, r in enumerate(reg[6:11]):\n",
    "#                 if r!=0:\n",
    "#                     arc2 = i+1\n",
    "\n",
    "#             for i, r in enumerate(reg[11:16]):\n",
    "#                 if r!=0:\n",
    "#                     arc3 = i+1\n",
    "\n",
    "#             temp_dic[reg[0]] = {'=': arc1, '>=': arc2, '<=': arc3} \n",
    "\n",
    "#         return temp_dic\n",
    "    \n",
    "    \n",
    "#     def Regularity_Generation(minSup, users, items):\n",
    "#         for u_id in users:\n",
    "#             support_matrix_users[udict[u_id], 0] = u_id\n",
    "#             for d in range(1, 6):\n",
    "#                 support_eq = data_csv[(data_csv['user'] == u_id) & (data_csv['rating'] == d)].shape[0]\n",
    "#                 support_eq_bg = data_csv[(data_csv['user'] == u_id) & (data_csv['rating'] >= d)].shape[0]\n",
    "#                 support_eq_sm = data_csv[(data_csv['user'] == u_id) & (data_csv['rating'] <= d)].shape[0]\n",
    "\n",
    "#                 support_matrix_users[udict[u_id], d] = support_eq if (support_eq > minSup) else 0\n",
    "#                 support_matrix_users[udict[u_id], d+5] = support_eq_bg if (support_eq_bg > minSup) else 0\n",
    "#                 support_matrix_users[udict[u_id], d+10] = support_eq_sm if (support_eq_sm > minSup) else 0\n",
    "\n",
    "#         for i_id in items:\n",
    "#             support_matrix_items[mdict[i_id], 0] = i_id\n",
    "#             for d in range(1, 6):\n",
    "#                 support_eq = data_csv[(data_csv['item'] == i_id) & (data_csv['rating'] == d)].shape[0]\n",
    "#                 support_eq_bg = data_csv[(data_csv['item'] == i_id) & (data_csv['rating'] >= d)].shape[0]\n",
    "#                 support_eq_sm = data_csv[(data_csv['item'] == i_id) & (data_csv['rating'] <= d)].shape[0]\n",
    "\n",
    "#                 support_matrix_items[mdict[i_id], d] = support_eq if (support_eq > minSup) else 0\n",
    "#                 support_matrix_items[mdict[i_id], d+5] = support_eq_bg if (support_eq_bg > minSup) else 0\n",
    "#                 support_matrix_items[mdict[i_id], d+10] = support_eq_sm if (support_eq_sm > minSup) else 0\n",
    "\n",
    "#         for row in support_matrix_users:\n",
    "#             temp = [x if (x == max(row[1:6])) or (x == max(row[6:11])) or (x == max(row[11:16])) else 0 for x in row[1:]]\n",
    "#             for i in range(15):\n",
    "#                 support_matrix_users[udict[row[0]], i+1] = temp[i]\n",
    "\n",
    "#         for row in support_matrix_items:\n",
    "#             temp = [x if (x == max(row[1:6])) or (x == max(row[6:11])) or (x == max(row[11:16])) else 0 for x in row[1:]]\n",
    "#             for i in range(15):\n",
    "#                 support_matrix_items[mdict[row[0]], i+1] = temp[i]\n",
    "\n",
    "#         dictUser = userItemSet(support_matrix_users)\n",
    "#         dictItem = userItemSet(support_matrix_items)\n",
    "\n",
    "#         return dictUser, dictItem\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def FindAnomalousRatingsPerUser(N, minSup, users, items):\n",
    "#         regForUsers, regForItems = Regularity_Generation(minSup, users, items)\n",
    "\n",
    "#         errorMatrix = np.zeros((n_u, n_m), dtype='float32')\n",
    "\n",
    "\n",
    "#         for u_id, values in regForUsers.items():\n",
    "#             for i in items:\n",
    "#                 r = matrix[udict[u_id], mdict[i]]\n",
    "#                 if (r!=0) and (values['='] != 0) and (values['='] != r) and (values['=']+1 != r) and (values['=']-1 != r):\n",
    "#                     errorMatrix[udict[u_id], mdict[i]] = values['='] - r\n",
    "\n",
    "\n",
    "#         for i_id, values in regForItems.items():\n",
    "#             for u in users:\n",
    "#                 r = matrix[udict[u], mdict[i_id]]\n",
    "#                 if (r!=0) and (values['='] != 0) and (values['='] != r) and (values['=']+1 != r) and (values['=']-1 != r):\n",
    "#                     if errorMatrix[udict[u], mdict[i_id]] == 0:\n",
    "#                         errorMatrix[udict[u], mdict[i_id]] = values['='] - r\n",
    "#                     else:\n",
    "#                         errorMatrix[udict[u], mdict[i_id]] = (errorMatrix[udict[u], mdict[i_id]] + values['='] - r)/2.0\n",
    "\n",
    "\n",
    "#         anomalousItemsPerUserList = {}\n",
    "#         for u in users:\n",
    "#             temp = {}\n",
    "#             for i, t in enumerate(errorMatrix[udict[u]]):\n",
    "#                 if t != 0:\n",
    "#                     temp[i] = t\n",
    "\n",
    "\n",
    "#             # Reduce dictionary  \n",
    "#             if len(temp) >= N:\n",
    "#                 s = 0\n",
    "#                 temp_cropped = {}\n",
    "#                 temp_sorted = {i: value for i, value in sorted(temp.items(), key=lambda item: item[1], reverse=True)}\n",
    "#                 for i, value in temp_sorted.items():\n",
    "#                     s += 1\n",
    "#                     temp_cropped[i] = value\n",
    "#                     if s >= N:\n",
    "#                         break\n",
    "#                 anomalousItemsPerUserList[udict[u]] = temp_cropped\n",
    "#             else:\n",
    "#                 anomalousItemsPerUserList[udict[u]] = temp\n",
    "\n",
    "#         return anomalousItemsPerUserList\n",
    "    \n",
    "    \n",
    "#     def Correction(diff, N, minSup, users, items):\n",
    "#         anomalousItemsPerUserList = FindAnomalousRatingsPerUser(N, minSup, users, items)\n",
    "\n",
    "#         for u in users:            \n",
    "#             for i, values in anomalousItemsPerUserList[udict[u]].items():\n",
    "#                 if values > diff:\n",
    "#                     matrix[udict[u], i] += values\n",
    "\n",
    "#         return anomalousItemsPerUserList, matrix\n",
    "    \n",
    "#  # //////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#     # Run\n",
    "#     toc = time()\n",
    "#     anomalousItemsPerUserList, matrix = Correction(diff, N, minSup, users, items)\n",
    "#     print('Preprocessing time: {} seconds!'.format(int(time() - toc)))\n",
    "    \n",
    "#     new_data = []\n",
    "#     for u in users:\n",
    "#         for i in items:\n",
    "#             r = matrix[udict[u], mdict[i]]\n",
    "#             if r != 0:\n",
    "#                 new_data.append([u, i, r])\n",
    "                \n",
    "#     new_data = np.array(new_data).astype('int32')\n",
    "    \n",
    "# #  //////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "#     # shuffle indices\n",
    "#     idx = np.arange(n_r)\n",
    "#     np.random.shuffle(idx)\n",
    "\n",
    "#     trainRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "#     validRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "\n",
    "#     for i in range(n_r):\n",
    "#         u_id = new_data[idx[i], 0]\n",
    "#         m_id = new_data[idx[i], 1]\n",
    "#         r = new_data[idx[i], 2]\n",
    "\n",
    "#         # the first few ratings of the shuffled data array are validation data\n",
    "#         if i <= valfrac * n_r:\n",
    "#             validRatings[udict[u_id], mdict[m_id]] = float(r)     # [index(0..6039), index(0..3705)] = r\n",
    "#         # the rest are training data\n",
    "#         else:\n",
    "#             trainRatings[udict[u_id], mdict[m_id]] = float(r)     # [index(0..6039), index(0..3705)] = r\n",
    "\n",
    "#     if transpose:\n",
    "#         trainRatings = trainRatings.T\n",
    "#         validRatings = validRatings.T\n",
    "\n",
    "#     print('loaded dense data matrix')\n",
    "#     print('\\nAll data preprocessed: {:0.2f} seconds!'.format(time() - tic))\n",
    "#     print('\\n------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "#     return trainRatings, validRatings, data, idx, data_csv, anomalousItemsPerUserList, matrix, new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr, vr, data, idx, data_csv, anomalousItemsPerUserList, matrix, new_data = loadData('./datasets/ml-1M.dat', valfrac=0.1, delimiter='::', seed=1593523459, transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from time import time\n",
    "\n",
    "\n",
    "# def loadData(path='./', valfrac=0.1, delimiter='::', seed=1234, transpose=False):\n",
    "#     '''\n",
    "#     Loads the Dataset: 'ml-1M.dat'\n",
    "    \n",
    "#     :param path: path to the ratings file\n",
    "#     :param valfrac: fraction of data to use for validation\n",
    "#     :param delimiter: delimiter used in data file\n",
    "#     :param seed: random seed for validation splitting\n",
    "#     :param transpose: flag to transpose output matrices (swapping users with movies)\n",
    "#     :return: train ratings (n_u, n_m), valid ratings (n_u, n_m)\n",
    "#     '''\n",
    "#     tic = time()\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "    \n",
    "#     print('reading data...')\n",
    "#     data = np.loadtxt(path, skiprows=0, delimiter=delimiter).astype('int32')  # .dat file\n",
    "#     print('\\ndata read in: {:0.2f} seconds!'.format(time() - tic))\n",
    "\n",
    "#     data_csv = pd.DataFrame(data, columns = ['user', 'item', 'rating', 'timestamp'])\n",
    "#     data_csv.sort_values(['user', 'item'], ascending=[True, True], inplace=True)\n",
    "#     data_csv.reset_index(inplace=True)\n",
    "#     data_csv.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "#     data_sorted = np.array(data_csv)\n",
    "\n",
    "# # HERE\n",
    "\n",
    "#     users = np.unique(data[:, 0]).tolist() # list of unique users\n",
    "#     items = np.unique(data[:, 1]).tolist() # list of unique items\n",
    "    \n",
    "#     n_u = len(users)     # number of users\n",
    "#     n_m = len(items)     # number of movies\n",
    "#     n_r = data.shape[0]  # number of ratings\n",
    "\n",
    "#     # these dictionaries define a mapping from user/movie id to to user/movie number (contiguous from zero)\n",
    "#     udict = {}        # {id_u: index(0..6039)}\n",
    "#     for i, u in enumerate(users):\n",
    "#         udict[u] = i\n",
    "#     mdict = {}        # {id_m: index(0..3705)}\n",
    "#     for i, m in enumerate(items):\n",
    "#         mdict[m] = i\n",
    "\n",
    "#     support_matrix_users = np.zeros((n_u, 16), dtype='int32')\n",
    "#     support_matrix_items = np.zeros((n_m, 16), dtype='int32')\n",
    "#     matrix = np.zeros((n_u, n_m), dtype='float')    \n",
    "    \n",
    "#     for i in range(n_r):\n",
    "#         u_id = data[i, 0]\n",
    "#         m_id = data[i, 1]\n",
    "#         r = data[i, 2]\n",
    "\n",
    "#         matrix[udict[u_id], mdict[m_id]] = int(r)\n",
    "    \n",
    "    \n",
    "#     def userItemSet(regul):\n",
    "#         temp_dic = dict()       \n",
    "#         for reg in regul:\n",
    "#             temp = []\n",
    "#             arc1 = 0\n",
    "#             arc2 = 0\n",
    "#             arc3 = 0\n",
    "\n",
    "#             for i, r in enumerate(reg[1:6]):\n",
    "#                 if r!=0:\n",
    "#                     arc1 = i+1\n",
    "\n",
    "#             for i, r in enumerate(reg[6:11]):\n",
    "#                 if r!=0:\n",
    "#                     arc2 = i+1\n",
    "\n",
    "#             for i, r in enumerate(reg[11:16]):\n",
    "#                 if r!=0:\n",
    "#                     arc3 = i+1\n",
    "\n",
    "#             temp_dic[reg[0]] = {'=': arc1, '>=': arc2, '<=': arc3} \n",
    "\n",
    "#         return temp_dic\n",
    "    \n",
    "    \n",
    "#     def Regularity_Generation(minSup, users, items):\n",
    "#         for u_id in users:\n",
    "#             support_matrix_users[udict[u_id], 0] = u_id\n",
    "#             for d in range(1, 6):\n",
    "#                 support_eq = data_csv[(data_csv['user'] == u_id) & (data_csv['rating'] == d)].shape[0]\n",
    "#                 support_eq_bg = data_csv[(data_csv['user'] == u_id) & (data_csv['rating'] >= d)].shape[0]\n",
    "#                 support_eq_sm = data_csv[(data_csv['user'] == u_id) & (data_csv['rating'] <= d)].shape[0]\n",
    "\n",
    "#                 support_matrix_users[udict[u_id], d] = support_eq if (support_eq > minSup) else 0\n",
    "#                 support_matrix_users[udict[u_id], d+5] = support_eq_bg if (support_eq_bg > minSup) else 0\n",
    "#                 support_matrix_users[udict[u_id], d+10] = support_eq_sm if (support_eq_sm > minSup) else 0\n",
    "\n",
    "#         for i_id in items:\n",
    "#             support_matrix_items[mdict[i_id], 0] = i_id\n",
    "#             for d in range(1, 6):\n",
    "#                 support_eq = data_csv[(data_csv['item'] == i_id) & (data_csv['rating'] == d)].shape[0]\n",
    "#                 support_eq_bg = data_csv[(data_csv['item'] == i_id) & (data_csv['rating'] >= d)].shape[0]\n",
    "#                 support_eq_sm = data_csv[(data_csv['item'] == i_id) & (data_csv['rating'] <= d)].shape[0]\n",
    "\n",
    "#                 support_matrix_items[mdict[i_id], d] = support_eq if (support_eq > minSup) else 0\n",
    "#                 support_matrix_items[mdict[i_id], d+5] = support_eq_bg if (support_eq_bg > minSup) else 0\n",
    "#                 support_matrix_items[mdict[i_id], d+10] = support_eq_sm if (support_eq_sm > minSup) else 0\n",
    "\n",
    "#         for row in support_matrix_users:\n",
    "#             temp = [x if (x == max(row[1:6])) or (x == max(row[6:11])) or (x == max(row[11:16])) else 0 for x in row[1:]]\n",
    "#             for i in range(15):\n",
    "#                 support_matrix_users[udict[row[0]], i+1] = temp[i]\n",
    "\n",
    "#         for row in support_matrix_items:\n",
    "#             temp = [x if (x == max(row[1:6])) or (x == max(row[6:11])) or (x == max(row[11:16])) else 0 for x in row[1:]]\n",
    "#             for i in range(15):\n",
    "#                 support_matrix_items[mdict[row[0]], i+1] = temp[i]\n",
    "\n",
    "#         dictUser = userItemSet(support_matrix_users)\n",
    "#         dictItem = userItemSet(support_matrix_items)\n",
    "\n",
    "#         return dictUser, dictItem\n",
    "    \n",
    "    \n",
    "#     def FindAnomalousRatingsPerUser(N, minSup, users, items):\n",
    "#         regForUsers, regForItems = Regularity_Generation(minSup, users, items)\n",
    "\n",
    "#         errorMatrix = np.zeros((n_u, n_m), dtype='float32')\n",
    "\n",
    "\n",
    "#         for u_id, values in regForUsers.items():\n",
    "#             for i in items:\n",
    "#                 r = matrix[udict[u_id], mdict[i]]\n",
    "#                 if (r!=0) and (values['='] != 0) and (values['='] != r) and (values['=']+1 != r) and (values['=']-1 != r):\n",
    "#                     errorMatrix[udict[u_id], mdict[i]] = values['='] - r\n",
    "\n",
    "\n",
    "#         for i_id, values in regForItems.items():\n",
    "#             for u in users:\n",
    "#                 r = matrix[udict[u], mdict[i_id]]\n",
    "#                 if (r!=0) and (values['='] != 0) and (values['='] != r) and (values['=']+1 != r) and (values['=']-1 != r):\n",
    "#                     if errorMatrix[udict[u], mdict[i_id]] == 0:\n",
    "#                         errorMatrix[udict[u], mdict[i_id]] = values['='] - r\n",
    "#                     else:\n",
    "#                         errorMatrix[udict[u], mdict[i_id]] = (errorMatrix[udict[u], mdict[i_id]] + values['='] - r)/2.0\n",
    "\n",
    "\n",
    "#         anomalousItemsPerUserList = {}\n",
    "#         for u in users:\n",
    "#             temp = {}\n",
    "#             for i, t in enumerate(errorMatrix[udict[u]]):\n",
    "#                 if t != 0:\n",
    "#                     temp[i] = t\n",
    "\n",
    "\n",
    "#             # Reduce dictionary  \n",
    "#             if len(temp) >= N:\n",
    "#                 s = 0\n",
    "#                 temp_cropped = {}\n",
    "#                 temp_sorted = {i: value for i, value in sorted(temp.items(), key=lambda item: item[1], reverse=True)}\n",
    "#                 for i, value in temp_sorted.items():\n",
    "#                     s += 1\n",
    "#                     temp_cropped[i] = value\n",
    "#                     if s >= N:\n",
    "#                         break\n",
    "#                 anomalousItemsPerUserList[udict[u]] = temp_cropped\n",
    "#             else:\n",
    "#                 anomalousItemsPerUserList[udict[u]] = temp\n",
    "\n",
    "#         return anomalousItemsPerUserList\n",
    "    \n",
    "    \n",
    "#     def Correction(diff, N, minSup, users, items):\n",
    "#         anomalousItemsPerUserList = FindAnomalousRatingsPerUser(N, minSup, users, items)\n",
    "\n",
    "#         for u in users:            \n",
    "#             for i, values in anomalousItemsPerUserList[udict[u]].items():\n",
    "#                 if abs(values) > diff:\n",
    "#                     matrix[udict[u], i] += values\n",
    "\n",
    "#         return anomalousItemsPerUserList, matrix\n",
    "    \n",
    "    \n",
    "#  # //////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# #     # MovieLens 1M #1     11111111111111111111111\n",
    "# #     N = 50\n",
    "# #     diff = 1.5\n",
    "# #     minSup = 430\n",
    "\n",
    "# #     # MovieLens 1M #2     all=7459     <= 15\n",
    "# #     N = 50\n",
    "# #     diff = 1.5\n",
    "# #     minSup = 1000\n",
    "# # # RMSE = 0.814467\n",
    "\n",
    "# #     # MovieLens 1M #3     11111111111111111111111\n",
    "# #     N = 50\n",
    "# #     diff = 2.0\n",
    "# #     minSup = 430\n",
    "\n",
    "# #     # MovieLens 1M #4     11111111111111111111111\n",
    "# #     N = 5\n",
    "# #     diff = 1.5\n",
    "# #     minSup = 430\n",
    "\n",
    "#  # //////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "#     # MovieLens 1M #1     all=18367     5=2387\n",
    "#     N = 5\n",
    "#     diff = 2.0\n",
    "#     minSup = 430\n",
    "# # RMSE: 0.810243\n",
    "\n",
    "# #     # MovieLens 1M #2     all=18095     5=2310\n",
    "# #     N = 5\n",
    "# #     diff = 2.0\n",
    "# #     minSup = 450\n",
    "# # RMSE: 0.810796\n",
    "\n",
    "\n",
    "# #     # MovieLens 1M #3     all=16664     5=1972\n",
    "# #     N = 5\n",
    "# #     diff = 2.0\n",
    "# #     minSup = 500\n",
    "# # RMSE: 0.812836\n",
    "\n",
    "# #     # MovieLens 1M #4     all=13992     5=1394 \n",
    "# #     N = 5\n",
    "# #     diff = 2.0\n",
    "# #     minSup = 600\n",
    "# # RMSE: 0.815510\n",
    "\n",
    "# #     # MovieLens 1M #5     all=10183     5=737\n",
    "# #     N = 5\n",
    "# #     diff = 2.0\n",
    "# #     minSup = 800\n",
    "# # RMSE: 0.819419\n",
    "\n",
    "#  # //////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "#     # Run\n",
    "#     toc = time()\n",
    "#     anomalousItemsPerUserList, matrix = Correction(diff, N, minSup, users, items)\n",
    "#     print('Preprocessing time: {} seconds!'.format(int(time() - toc)))\n",
    "    \n",
    "#     # Build a new table of data  \n",
    "#     new_ratings = matrix.reshape(-1, 1)\n",
    "#     new_ratings = new_ratings[new_ratings != 0].reshape(-1, 1).astype('int32')\n",
    "    \n",
    "#     new_data = np.hstack((data_sorted[:,:2], new_ratings))\n",
    "\n",
    "# #  //////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "#     # shuffle indices\n",
    "#     idx = np.arange(n_r)\n",
    "#     np.random.shuffle(idx)\n",
    "\n",
    "#     trainRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "#     validRatings = np.zeros((n_u, n_m), dtype='float32')\n",
    "\n",
    "#     for i in range(n_r):\n",
    "#         u_id = new_data[idx[i], 0]\n",
    "#         m_id = new_data[idx[i], 1]\n",
    "#         r = new_data[idx[i], 2]\n",
    "\n",
    "#         # the first few ratings of the shuffled data array are validation data\n",
    "#         if i <= valfrac * n_r:\n",
    "#             validRatings[udict[u_id], mdict[m_id]] = float(r)     # [index(0..6039), index(0..3705)] = r\n",
    "#         # the rest are training data\n",
    "#         else:\n",
    "#             trainRatings[udict[u_id], mdict[m_id]] = float(r)     # [index(0..6039), index(0..3705)] = r\n",
    "\n",
    "#     if transpose:\n",
    "#         trainRatings = trainRatings.T\n",
    "#         validRatings = validRatings.T\n",
    "\n",
    "#     print('loaded dense data matrix')\n",
    "#     print('\\nAll data preprocessed: {:0.2f} seconds!'.format(time() - tic))\n",
    "#     print('\\n------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "#     return trainRatings, validRatings, anomalousItemsPerUserList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
