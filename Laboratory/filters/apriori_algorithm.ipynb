{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriory Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "from time import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_group(*args):\n",
    "    return str(sorted(args))\n",
    "\n",
    "\n",
    "def generate_pairs(*args):\n",
    "    pairs = []\n",
    "    for idx_1 in range(len(args) - 1):\n",
    "        for idx_2 in range(idx_1 + 1, len(args)):\n",
    "            pairs.append(normalize_group(args[idx_1], args[idx_2]))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def generate_triples(*args):\n",
    "    triples = []\n",
    "    for idx_1 in range(len(args) - 2):\n",
    "        for idx_2 in range(idx_1 + 1, len(args) - 1):\n",
    "            for idx_3 in range(idx_2 + 1, len(args)):\n",
    "                triples.append(normalize_group(args[idx_1], args[idx_2], args[idx_3]))\n",
    "    return triples\n",
    "\n",
    "\n",
    "def generate_fourfolds(*args):\n",
    "    fourfolds = []\n",
    "    for idx_1 in range(len(args) - 3):\n",
    "        for idx_2 in range(idx_1 + 1, len(args) - 2):\n",
    "            for idx_3 in range(idx_2 + 1, len(args) - 1):\n",
    "                for idx_4 in range(idx_3 + 1, len(args)):\n",
    "                    fourfolds.append(normalize_group(args[idx_1], args[idx_2], args[idx_3], args[idx_4]))\n",
    "    return fourfolds\n",
    "\n",
    "\n",
    "def separator(regularities):\n",
    "    regularities_ID_R = []\n",
    "    single_unique_terms = set()\n",
    "    \n",
    "    for reg in regularities:\n",
    "        terms = re.split('\\[\\'|\\', \\'|\\'\\]', reg[0])[1:-1]\n",
    "        for term in terms: single_unique_terms.add(term)\n",
    "        \n",
    "    for unique_term in single_unique_terms:\n",
    "        ID_R = re.split('Item_|: ', unique_term)[1:]\n",
    "        regularities_ID_R.append(list(map(int, ID_R)))\n",
    "            \n",
    "    return single_unique_terms, regularities_ID_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriory_algorithm(THRESHOLD=30, file='../datasets/filter_2/file_100K.txt'):\n",
    "    tic = time()\n",
    "    THRESHOLD = THRESHOLD\n",
    "    \n",
    "    frequent_items = set()\n",
    "    frequent_pairs = set()\n",
    "    frequent_triples = set()\n",
    "    frequent_fourfold = set()\n",
    "    frequent_fivefold = set()\n",
    "    \n",
    "    item_counts = defaultdict(int)\n",
    "    pair_counts = defaultdict(int)\n",
    "    triple_counts = defaultdict(int)\n",
    "    fourfold_counts = defaultdict(int)\n",
    "    fivefold_counts = defaultdict(int)\n",
    "    \n",
    "    # read in the data\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "    # FIRST PASS ----------------------------------------------------------------------------------\n",
    "\n",
    "    # first pass - find candidate items\n",
    "    for line in lines:\n",
    "        for item in line.split(', '):\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    # first pass - find frequent items\n",
    "    for key in item_counts:\n",
    "        if item_counts[key] > THRESHOLD:\n",
    "            frequent_items.add(key)\n",
    "            \n",
    "    print('There are {0} unique items, {1} of which are frequent'.format(len(item_counts), len(frequent_items)))\n",
    "    \n",
    "    \n",
    "    # SECOND PASS ----------------------------------------------------------------------------------\n",
    "\n",
    "    # second pass - find candidate pairs\n",
    "    # when building candidate pairs, only consider frequent items\n",
    "    for line in lines:\n",
    "        items = line.split(', ')\n",
    "        for idx_1 in range(len(items) - 1):\n",
    "            if items[idx_1] not in frequent_items:\n",
    "                continue\n",
    "            for idx_2 in range(idx_1 + 1, len(items)):\n",
    "                if items[idx_2] not in frequent_items:\n",
    "                    continue\n",
    "                pair = normalize_group(items[idx_1], items[idx_2]) # [a, b] is the same as [b, a]\n",
    "                pair_counts[pair] += 1\n",
    "\n",
    "    # second pass - find frequent pairs\n",
    "    for key in pair_counts:\n",
    "        if pair_counts[key] > THRESHOLD:\n",
    "            frequent_pairs.add(key)\n",
    "\n",
    "    print('There are {0} candidate pairs, {1} of which are frequent'.format(len(pair_counts), len(frequent_pairs)))\n",
    "    \n",
    "    \n",
    "    # THIRD PASS ----------------------------------------------------------------------------------\n",
    "\n",
    "    # third pass - find candidate triples\n",
    "    # when building candidate triples, only consider frequent items and pairs\n",
    "    if len(frequent_pairs) != 0: \n",
    "        for line in lines:\n",
    "            items = line.split(', ')\n",
    "            for idx_1 in range(len(items) - 2):\n",
    "                if items[idx_1] not in frequent_items:\n",
    "                    continue\n",
    "                for idx_2 in range(idx_1 + 1, len(items) - 1):\n",
    "                    first_pair = normalize_group(items[idx_1], items[idx_2])\n",
    "                    if items[idx_2] not in frequent_items or first_pair not in frequent_pairs:\n",
    "                        continue\n",
    "                    for idx_3 in range(idx_2 + 1, len(items)):\n",
    "                        if items[idx_3] not in frequent_items:\n",
    "                            continue\n",
    "                        # now check that all pairs are frequent, since this is a precondition to being a frequent triple\n",
    "                        pairs = generate_pairs(items[idx_1], items[idx_2], items[idx_3])\n",
    "                        if any(pair not in frequent_pairs for pair in pairs):\n",
    "                            continue\n",
    "                        triple = normalize_group(items[idx_1], items[idx_2], items[idx_3])\n",
    "                        triple_counts[triple] += 1\n",
    "\n",
    "        # third pass - find frequent triples\n",
    "        for key in triple_counts:\n",
    "            if triple_counts[key] > THRESHOLD:\n",
    "                frequent_triples.add(key)\n",
    "\n",
    "        print('There are {0} candidate triples, {1} of which are frequent'.format(len(triple_counts), len(frequent_triples)))\n",
    "    \n",
    "    \n",
    "\n",
    "    # FOURTH PASS ----------------------------------------------------------------------------------\n",
    "        \n",
    "    # fourth pass - find candidate fourfold\n",
    "    # when building candidate fourfold, only consider frequent items, pairs, and triples\n",
    "    if len(frequent_triples) != 0:\n",
    "        for line in lines:\n",
    "            items = line.split(', ')\n",
    "            for idx_1 in range(len(items) - 3):\n",
    "                if items[idx_1] not in frequent_items: # first item must be frequent\n",
    "                    continue\n",
    "                for idx_2 in range(idx_1 + 1, len(items) - 2):\n",
    "                    first_pair = normalize_group(items[idx_1], items[idx_2])\n",
    "                    if items[idx_2] not in frequent_items or first_pair not in frequent_pairs:\n",
    "                        continue\n",
    "                    for idx_3 in range(idx_2 + 1, len(items) - 1):\n",
    "                        second_pair = normalize_group(items[idx_1], items[idx_2], items[idx_3])\n",
    "                        if items[idx_3] not in frequent_items or second_pair not in frequent_triples:\n",
    "                            continue   \n",
    "                        for idx_4 in range(idx_3 + 1, len(items)):\n",
    "                            if items[idx_4] not in frequent_items:\n",
    "                                continue\n",
    "                            # now check that all triples are frequent, since this is a precondition to being a frequent fourfold\n",
    "                            triples = generate_triples(items[idx_1], items[idx_2], items[idx_3], items[idx_4])\n",
    "                            if any(trip not in frequent_triples for trip in triples):\n",
    "                                continue\n",
    "                            fourfold = normalize_group(items[idx_1], items[idx_2], items[idx_3], items[idx_4])\n",
    "                            fourfold_counts[fourfold] += 1\n",
    "\n",
    "        # fourth pass - find frequent fourfold\n",
    "        for key in fourfold_counts:\n",
    "            if fourfold_counts[key] > THRESHOLD:\n",
    "                frequent_fourfold.add(key)\n",
    "\n",
    "        print('There are {0} candidate fourfold, {1} of which are frequent'.format(len(fourfold_counts), len(frequent_fourfold)))\n",
    "    \n",
    "    \n",
    "    # FIFTH PASS -----------------------------------------\n",
    "\n",
    "    # fifth pass - find candidate fivefold\n",
    "    # when building candidate fivefold, only consider frequent items, pairs, triples, and fourfold\n",
    "    if len(frequent_fourfold) != 0:\n",
    "        for line in lines:\n",
    "            items = line.split(', ')\n",
    "            for idx_1 in range(len(items) - 4):\n",
    "                if items[idx_1] not in frequent_items:\n",
    "                    continue\n",
    "                for idx_2 in range(idx_1 + 1, len(items) - 3):\n",
    "                    first_pair = normalize_group(items[idx_1], items[idx_2])\n",
    "                    if items[idx_2] not in frequent_items or first_pair not in frequent_pairs:\n",
    "                        continue\n",
    "                    for idx_3 in range(idx_2 + 1, len(items) - 2):\n",
    "                        second_pair = normalize_group(items[idx_1], items[idx_2], items[idx_3])\n",
    "                        if items[idx_3] not in frequent_items or second_pair not in frequent_triples:\n",
    "                            continue\n",
    "                        for idx_4 in range(idx_3 + 1, len(items) - 1):\n",
    "                            third_pair = normalize_group(items[idx_1], items[idx_2], items[idx_3], items[idx_4])\n",
    "                            if items[idx_4] not in frequent_items or third_pair not in frequent_fourfold:\n",
    "                                continue\n",
    "                            for idx_5 in range(idx_4 + 1, len(items)):\n",
    "                                if items[idx_5] not in frequent_items:\n",
    "                                    continue\n",
    "                                # now check that all fourfold are frequent, since this is a precondition to being a frequent fivefold\n",
    "                                fourfolds = generate_fourfolds(items[idx_1], items[idx_2], items[idx_3], items[idx_4], items[idx_5])\n",
    "                                if any(four not in frequent_fourfold for four in fourfolds):\n",
    "                                    continue\n",
    "                                fivefold = normalize_group(items[idx_1], items[idx_2], items[idx_3], items[idx_4], items[idx_5])\n",
    "                                fivefold_counts[fivefold] += 1\n",
    "\n",
    "        # fifth pass - find frequent fivefold\n",
    "        for key in fivefold_counts:\n",
    "            if fivefold_counts[key] > THRESHOLD:\n",
    "                frequent_fivefold.add(key)\n",
    "\n",
    "        print('There are {0} candidate fivefold, {1} of which are frequent'.format(len(fivefold_counts), len(frequent_fivefold))) \n",
    "\n",
    "    \n",
    "    # VIEW OUR RESULTS -------------------------------------------------------------------------------\n",
    "    print('--------------')\n",
    "    \n",
    "    if len(frequent_fivefold) != 0:\n",
    "        fold_counts = fivefold_counts\n",
    "    elif len(frequent_fourfold) != 0:\n",
    "        fold_counts = fourfold_counts     \n",
    "    elif len(frequent_triples) != 0:\n",
    "        fold_counts = triple_counts     \n",
    "    elif len(frequent_pairs) != 0:\n",
    "        fold_counts = pair_counts\n",
    "    else:\n",
    "        fold_counts = item_counts\n",
    "    \n",
    "    frequent_folds = { k: v for k, v in fold_counts.items() if v > THRESHOLD }         # Get frequent fourfolds + counts\n",
    "    sorted_frequent_folds = sorted(frequent_folds.items(), key=operator.itemgetter(1)) # Sorted by count of Supports\n",
    "\n",
    "    for entry in sorted_frequent_folds:\n",
    "        print('{0}: {1}'.format(entry[0], entry[1]))\n",
    "        \n",
    "    print('Preprocessing time: {} mins!'.format(int((time() - tic) / 60.0)))\n",
    "        \n",
    "    return sorted_frequent_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MovieLens 100K\n",
    "# 1th PASS: There are 7249 unique items, 923 of which are frequent\n",
    "# 2th PASS: There are 411802 candidate pairs, 3410 of which are frequent\n",
    "# 3th PASS: There are 28879 candidate triples, 771 of which are frequent\n",
    "# 4th PASS: There are 465 candidate fourfold, 118 of which are frequent\n",
    "# 5th PASS: There are 9 candidate fivefold, 7 of which are frequent         ****\n",
    "\n",
    "# MovieLens 1M 300\n",
    "# 1th PASS: There are 18069 unique items, 598 of which are frequent\n",
    "# 2th PASS: There are 178208 candidate pairs, 659 of which are frequent\n",
    "# 3th PASS: There are 2823 candidate triples, 151 of which are frequent\n",
    "# 4th PASS: There are 35 candidate fourfold, 6 of which are frequent         ****\n",
    "\n",
    "# MovieLens 1M 430\n",
    "# 1th PASS: There are 18069 unique items, 280 of which are frequent\n",
    "# 2th PASS: There are 38955 candidate pairs, 167 of which are frequent\n",
    "# 3th PASS: There are 399 candidate triples, 11 of which are frequent        ****\n",
    "# 4th PASS: There are 1 candidate fourfold, 0 of which are frequent\n",
    "\n",
    "# MovieLens 1M 500\n",
    "# 1th PASS: There are 18069 unique items, 198 of which are frequent\n",
    "# 2th PASS: There are 19435 candidate pairs, 87 of which are frequent\n",
    "# 3th PASS: There are 163 candidate triples, 3 of which are frequent         ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
